# ğŸš€ End-to-End Data Engineering Project on Microsoft Azure 

## Overview
This solution showcases a fully automated data platform on Microsoft Azure that takes onâ€‘premises transactional data through a modern ETL pipeline, applies medallionâ€‘style transformations, and dynamically creates database objects.

---

## ğŸ¯ Business Objective

Enable organizations to:

- Modernize legacy SQL Server workflows  
- Automate daily data ingestion and transformation  
- Ensure data quality through standardized Bronzeâ€‘Silverâ€‘Gold layers  

---

## ğŸ› ï¸ Tech Stack

| Layer        | Technology                                     |
|--------------|------------------------------------------------|
| Ingestion    | Azure Data Factory (ADF), Self-Hosted IR       |
| Storage      | Azure Data Lake Storage Gen2 (ADLS)            |
| Processing   | Azure Databricks (PySpark)                     |
| Querying     | Azure Synapse Analytics (Serverless SQL)       |
| Visualization| Power BI                                       |
| Security     | Azure Key Vault, Azure Active Directory        |
| Versioning   | Git + GitHub                                   |

---

## Architecture

---

## âš™ï¸ Approach

1. **Ingestion**  
   - Configure Selfâ€‘Hosted Integration Runtime in a VM to simulate on-prem data source and pull tables from SQL Server.  
   - Parameterize pipelines for dynamic, scaleâ€‘out ingestion.  
   - ğŸ“º [Watch Setup & Ingestion in Azure Data Factory](https://youtu.be/GvwC8Uj5L2g)

2. **Medallion Architecture (Bronzeâ€“Silverâ€“Gold) Layers**  
   - **Bronze:** Raw data landing in Parquet format in ADLS.  
   - **Silver:** Cleaned & conformed Delta tables via Databricks notebooks.  
   - **Gold:** Aggregated, analyticsâ€‘ready Delta tables exposed via Synapse views.  
   - ğŸ“º [Watch Medallion Architecture and Transformation Flow](https://youtu.be/vDO5o7TdLqE)

3. **Processing with Databricks (PySpark)**  
   - Use notebooks to handle schema evolution, filtering, joins, and aggregations.  
   - Store curated data in Delta Lake format and register Delta tables.  
   - ğŸ“º [Watch Databricks Processing & Transformation](https://youtu.be/wR5JvF6uj1c)

4. **Automation & Orchestration**  
   - Trigger pipelines on schedule using ADF.  
   - Execute Databricks notebooks via ADF activity chains.

5. **Data Warehousing & Serving**  
   - Use Azure Synapse Serverless SQL Pools to create views on Gold Delta tables in ADLS.  
   - Expose curated data to BI tools.

6. **Security & Governance**  
   - Manage credentials and keys securely with Azure Key Vault.  
   - Apply RBAC using Azure Active Directory.

